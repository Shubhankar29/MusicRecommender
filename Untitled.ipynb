{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15cdf302",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4879f70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def music_recommender(userPreferences):\n",
    "        raw_data = pd.read_csv('genres_v2.csv', dtype={'song_name': 'str'})\n",
    "        print(raw_data.shape)\n",
    "        pd.set_option('display.max_columns', None)\n",
    "        raw_data.info()\n",
    "\n",
    "        # data cleaning --------------------------------------------------------------------------------------\n",
    "        nulls = raw_data.isnull().sum()\n",
    "        print(nulls)\n",
    "\n",
    "        training_data = raw_data.drop(['type', 'uri', 'track_href', 'analysis_url',\n",
    "                                       'song_name', 'Unnamed: 0', 'title', 'genre'], axis=1, inplace=False)\n",
    "\n",
    "        print(training_data.shape)\n",
    "        training_data = training_data[training_data.key != -1]\n",
    "        print(\"after dropping some rows:\\n\", training_data.shape)\n",
    "        print(training_data.head())\n",
    "\n",
    "        print(training_data.shape)\n",
    "        print(training_data.duplicated().any())\n",
    "        training_data.drop_duplicates(inplace=True)\n",
    "        print(training_data.shape)\n",
    "\n",
    "        training_data.hist()\n",
    "        plt.show()\n",
    "\n",
    "        # this global scalar will be fitted on training data and will be used for both training and test data\n",
    "        global_scalar = MinMaxScaler()\n",
    "        id_column = training_data['id']\n",
    "        training_data.drop(['id'], axis=1, inplace=True)\n",
    "        global_scalar.fit(training_data)\n",
    "        training_data = pd.DataFrame(global_scalar.transform(training_data),\n",
    "                                     index=training_data.index,\n",
    "                                     columns=training_data.columns)\n",
    "        training_data['id'] = id_column\n",
    "\n",
    "        training_data.hist()\n",
    "        plt.show()\n",
    "\n",
    "        training_data.info()\n",
    "\n",
    "        corr = training_data.corr()\n",
    "        sns.heatmap(corr[corr > 0.1], cmap=\"Blues\", annot=True)\n",
    "        plt.show()\n",
    "\n",
    "        # clustering ----------------------------------------------------------------------------------------\n",
    "\n",
    "        wcss = []\n",
    "        for i in range(1, 20):\n",
    "            kmeans = KMeans(i)\n",
    "            kmeans.fit(training_data.drop(['id'], axis=1, inplace=False))\n",
    "            wcss_iter = kmeans.inertia_\n",
    "            wcss.append(wcss_iter)\n",
    "\n",
    "        number_clusters = range(1, 20)\n",
    "        plt.plot(number_clusters, wcss)\n",
    "        plt.title('The Elbow title')\n",
    "        plt.xlabel('Number of clusters')\n",
    "        plt.ylabel('SSE')\n",
    "        plt.show()\n",
    "\n",
    "        kmeans = KMeans(n_clusters=10)\n",
    "        training_data_clustered = kmeans.fit(training_data.drop(['id'], axis=1, inplace=False))\n",
    "        training_data[\"cluster\"] = training_data_clustered.labels_\n",
    "        centroids = training_data_clustered.cluster_centers_\n",
    "        print(training_data.head())\n",
    "\n",
    "        # making output...........................................................................................\n",
    "        userPreferences.drop(userPreferences.columns.difference([\"danceability\", \"energy\", \"key\", \"loudness\", \"mode\",\n",
    "                                                                 \"speechiness\", \"acousticness\", \"instrumentalness\",\n",
    "                                                                 \"liveness\", \"valence\", \"tempo\", \"duration_ms\",\n",
    "                                                                 \"time_signature\"]), 1, inplace=True)\n",
    "\n",
    "        # input normalizing\n",
    "        userPreferences = pd.DataFrame(global_scalar.transform(userPreferences),\n",
    "                                       index=userPreferences.index,\n",
    "                                       columns=userPreferences.columns)\n",
    "\n",
    "        fields = [\"id\", \"cluster\"]\n",
    "\n",
    "        # single playlist\n",
    "        single_playlist = []\n",
    "        for i in range(5):\n",
    "            cluster_index = (training_data_clustered.predict(userPreferences.iloc[[i]]))[0]\n",
    "            print(cluster_index)\n",
    "            cluster_songs = training_data[training_data.cluster == cluster_index]\n",
    "            cluster_songs.drop(cluster_songs.columns.difference([\"id\", \"cluster\"]), 1, inplace=True)\n",
    "            single_playlist.append((cluster_songs.sample()).values.flatten().tolist())\n",
    "            print(single_playlist[i])\n",
    "\n",
    "        filename = \"single_playlist.csv\"\n",
    "\n",
    "        # writing to csv file\n",
    "        with open(filename, 'w') as csvfile:\n",
    "            # creating a csv writer object\n",
    "            csvwriter = csv.writer(csvfile)\n",
    "\n",
    "            # writing the fields\n",
    "            csvwriter.writerow(fields)\n",
    "\n",
    "            # writing the data rows\n",
    "            csvwriter.writerows(single_playlist)\n",
    "\n",
    "        # 5 playlists\n",
    "        for i in range(5):\n",
    "            ith_playlist = []\n",
    "            filename = \"pl\" + str(i + 1) + \".csv\"\n",
    "            cluster_index = (training_data_clustered.predict(userPreferences.iloc[[i]]))[0]\n",
    "            cluster_songs = training_data[training_data.cluster == cluster_index]\n",
    "            cluster_songs.drop(cluster_songs.columns.difference([\"id\", \"cluster\"]), 1, inplace=True)\n",
    "            for j in range(5):\n",
    "                ith_playlist.append((cluster_songs.sample()).values.flatten().tolist())\n",
    "\n",
    "            with open(filename, 'w') as csvfile:\n",
    "                # creating a csv writer object\n",
    "                csvwriter = csv.writer(csvfile)\n",
    "\n",
    "                # writing the fields\n",
    "                csvwriter.writerow(fields)\n",
    "\n",
    "                # writing the data rows\n",
    "                csvwriter.writerows(ith_playlist)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53c4dfd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\91932\\\\anaconda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py', '-f', 'C:\\\\Users\\\\91932\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-22c37f40-0af3-48a0-a70f-1f3e3ea4287b.json']\n",
      "File does not exist\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def main(args) -> None:\n",
    "    \"\"\" Main function to be called when the script is run from the command line. \n",
    "    This function will recommend songs based on the user's input and save the\n",
    "    playlist to a csv file.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    args: list \n",
    "        list of arguments from the command line (here is just the path of a file like input_tracks.csv)\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    arg_list = args[1:]\n",
    "    if len(arg_list) == 0:\n",
    "        print(\"Usage: python3 musicRecommender.py <csv file>\")\n",
    "        sys.exit()\n",
    "    else:\n",
    "        file_name = arg_list[0]\n",
    "        if not os.path.isfile(file_name):\n",
    "            print(\"File does not exist\")\n",
    "            sys.exit()\n",
    "        else:\n",
    "            userPreferences = pd.read_csv(file_name)\n",
    "            music_recommender(userPreferences)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\"get arguments from command line\n",
    "    you just have to write the name of the file that contains the users favorite tracks.\n",
    "    these tracks are now in input_tracks.csv \"\"\"\n",
    "    args = sys.argv\n",
    "    print(args)\n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ed1930",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
